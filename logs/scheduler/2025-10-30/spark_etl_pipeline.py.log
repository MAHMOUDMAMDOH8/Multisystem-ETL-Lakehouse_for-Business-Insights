[2025-10-30T08:47:55.614+0000] {processor.py:186} INFO - Started process (PID=452) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:47:55.615+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T08:47:55.618+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:47:55.618+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:47:55.663+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:47:55.653+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/spark_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_etl_pipeline.py", line 7, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 24, in <module>
    from airflow.providers.apache.spark.hooks.spark_submit import SparkSubmitHook
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py", line 35, in <module>
    from airflow.providers.common.compat.sdk import BaseHook
ModuleNotFoundError: No module named 'airflow.providers.common.compat.sdk'
[2025-10-30T08:47:55.664+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:47:55.690+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.083 seconds
[2025-10-30T08:48:26.222+0000] {processor.py:186} INFO - Started process (PID=467) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:48:26.223+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T08:48:26.225+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:48:26.225+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:48:26.248+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:48:26.243+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/spark_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_etl_pipeline.py", line 7, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 24, in <module>
    from airflow.providers.apache.spark.hooks.spark_submit import SparkSubmitHook
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py", line 35, in <module>
    from airflow.providers.common.compat.sdk import BaseHook
ModuleNotFoundError: No module named 'airflow.providers.common.compat.sdk'
[2025-10-30T08:48:26.249+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:48:26.269+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.052 seconds
[2025-10-30T08:48:56.821+0000] {processor.py:186} INFO - Started process (PID=482) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:48:56.822+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T08:48:56.825+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:48:56.824+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:48:56.850+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:48:56.845+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/spark_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_etl_pipeline.py", line 7, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 24, in <module>
    from airflow.providers.apache.spark.hooks.spark_submit import SparkSubmitHook
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py", line 35, in <module>
    from airflow.providers.common.compat.sdk import BaseHook
ModuleNotFoundError: No module named 'airflow.providers.common.compat.sdk'
[2025-10-30T08:48:56.851+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:48:56.871+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.055 seconds
[2025-10-30T08:49:27.497+0000] {processor.py:186} INFO - Started process (PID=503) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:49:27.498+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T08:49:27.502+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:49:27.501+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:49:27.536+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:49:27.527+0000] {dagbag.py:386} ERROR - Failed to import: /opt/airflow/dags/spark_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 382, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_etl_pipeline.py", line 7, in <module>
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 24, in <module>
    from airflow.providers.apache.spark.hooks.spark_submit import SparkSubmitHook
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py", line 35, in <module>
    from airflow.providers.common.compat.sdk import BaseHook
ModuleNotFoundError: No module named 'airflow.providers.common.compat.sdk'
[2025-10-30T08:49:27.537+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:49:27.572+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.081 seconds
[2025-10-30T08:53:45.434+0000] {processor.py:186} INFO - Started process (PID=172) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:53:45.439+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T08:53:45.443+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:53:45.442+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:53:45.492+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:53:45.727+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:53:45.726+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG:spark_etl_pipeline
[2025-10-30T08:53:45.738+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:53:45.738+0000] {override.py:1900} INFO - Created Permission View: can edit on DAG:spark_etl_pipeline
[2025-10-30T08:53:45.745+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:53:45.745+0000] {override.py:1900} INFO - Created Permission View: can read on DAG:spark_etl_pipeline
[2025-10-30T08:53:45.755+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:53:45.755+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG Run:spark_etl_pipeline
[2025-10-30T08:53:45.764+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:53:45.764+0000] {override.py:1900} INFO - Created Permission View: menu access on DAG Run:spark_etl_pipeline
[2025-10-30T08:53:45.771+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:53:45.771+0000] {override.py:1900} INFO - Created Permission View: can read on DAG Run:spark_etl_pipeline
[2025-10-30T08:53:45.779+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:53:45.779+0000] {override.py:1900} INFO - Created Permission View: can create on DAG Run:spark_etl_pipeline
[2025-10-30T08:53:45.780+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:53:45.780+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T08:53:45.793+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:53:45.793+0000] {dag.py:3252} INFO - Creating ORM DAG for spark_etl_pipeline
[2025-10-30T08:53:45.805+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:53:45.805+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T08:53:45.834+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.415 seconds
[2025-10-30T08:54:16.506+0000] {processor.py:186} INFO - Started process (PID=206) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:54:16.507+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T08:54:16.511+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:54:16.510+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:54:16.545+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:54:16.577+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:54:16.577+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T08:54:16.621+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:54:16.621+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T08:54:16.648+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.148 seconds
[2025-10-30T08:54:47.278+0000] {processor.py:186} INFO - Started process (PID=261) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:54:47.280+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T08:54:47.285+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:54:47.285+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:54:47.318+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:54:47.372+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:54:47.372+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T08:54:47.432+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:54:47.432+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T08:54:47.463+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.199 seconds
[2025-10-30T08:55:18.089+0000] {processor.py:186} INFO - Started process (PID=289) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:55:18.090+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T08:55:18.093+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:55:18.092+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:55:18.124+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:55:18.156+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:55:18.156+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T08:55:18.180+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:55:18.179+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T08:55:18.209+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.126 seconds
[2025-10-30T08:55:48.763+0000] {processor.py:186} INFO - Started process (PID=304) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:55:48.765+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T08:55:48.769+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:55:48.768+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:55:48.798+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:55:48.828+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:55:48.828+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T08:55:48.849+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:55:48.848+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T08:55:48.869+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.112 seconds
[2025-10-30T08:56:19.435+0000] {processor.py:186} INFO - Started process (PID=319) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:56:19.436+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T08:56:19.438+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:56:19.438+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:56:19.461+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:56:19.485+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:56:19.485+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T08:56:19.505+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:56:19.505+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T08:56:19.527+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.097 seconds
[2025-10-30T08:56:50.079+0000] {processor.py:186} INFO - Started process (PID=334) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:56:50.080+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T08:56:50.082+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:56:50.082+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:56:50.103+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:56:50.129+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:56:50.129+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T08:56:50.150+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:56:50.150+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T08:56:50.169+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.096 seconds
[2025-10-30T08:57:20.739+0000] {processor.py:186} INFO - Started process (PID=349) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:57:20.740+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T08:57:20.743+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:57:20.743+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:57:20.770+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:57:20.798+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:57:20.797+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T08:57:20.819+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:57:20.819+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T08:57:20.838+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.104 seconds
[2025-10-30T08:57:51.397+0000] {processor.py:186} INFO - Started process (PID=364) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:57:51.398+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T08:57:51.401+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:57:51.400+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:57:51.425+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:57:51.452+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:57:51.451+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T08:57:51.471+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:57:51.471+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T08:57:51.491+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.100 seconds
[2025-10-30T08:58:22.042+0000] {processor.py:186} INFO - Started process (PID=379) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:58:22.043+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T08:58:22.046+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:58:22.045+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:58:22.068+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:58:22.095+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:58:22.095+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T08:58:22.115+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:58:22.115+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T08:58:22.136+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.099 seconds
[2025-10-30T08:58:52.815+0000] {processor.py:186} INFO - Started process (PID=394) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:58:52.817+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T08:58:52.819+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:58:52.819+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:58:52.848+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:58:52.875+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:58:52.874+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T08:58:52.894+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:58:52.894+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T08:58:52.913+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.104 seconds
[2025-10-30T08:59:23.435+0000] {processor.py:186} INFO - Started process (PID=409) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:59:23.437+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T08:59:23.439+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:59:23.439+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:59:23.465+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:59:23.493+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:59:23.493+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T08:59:23.513+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:59:23.513+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T08:59:23.529+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.099 seconds
[2025-10-30T08:59:54.322+0000] {processor.py:186} INFO - Started process (PID=424) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:59:54.324+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T08:59:54.327+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:59:54.326+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:59:54.357+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T08:59:54.385+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:59:54.385+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T08:59:54.406+0000] {logging_mixin.py:190} INFO - [2025-10-30T08:59:54.406+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T08:59:54.424+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.108 seconds
[2025-10-30T09:00:24.982+0000] {processor.py:186} INFO - Started process (PID=439) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:00:24.983+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:00:24.986+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:00:24.985+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:00:25.011+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:00:25.036+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:00:25.035+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:00:25.055+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:00:25.055+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:00:25.076+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.100 seconds
[2025-10-30T09:00:55.656+0000] {processor.py:186} INFO - Started process (PID=454) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:00:55.657+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:00:55.660+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:00:55.659+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:00:55.686+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:00:55.713+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:00:55.713+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:00:55.733+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:00:55.733+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:00:55.756+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.105 seconds
[2025-10-30T09:01:26.307+0000] {processor.py:186} INFO - Started process (PID=469) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:01:26.309+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:01:26.311+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:01:26.311+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:01:26.338+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:01:26.364+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:01:26.364+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:01:26.385+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:01:26.385+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:01:26.403+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.102 seconds
[2025-10-30T09:01:56.927+0000] {processor.py:186} INFO - Started process (PID=484) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:01:56.928+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:01:56.931+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:01:56.931+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:01:56.957+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:01:56.984+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:01:56.984+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:01:57.004+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:01:57.004+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:01:57.023+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.102 seconds
[2025-10-30T09:02:27.612+0000] {processor.py:186} INFO - Started process (PID=499) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:02:27.613+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:02:27.616+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:02:27.615+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:02:27.640+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:02:27.669+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:02:27.669+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:02:27.692+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:02:27.691+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:02:27.710+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.104 seconds
[2025-10-30T09:02:58.251+0000] {processor.py:186} INFO - Started process (PID=514) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:02:58.252+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:02:58.255+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:02:58.255+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:02:58.277+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:02:58.303+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:02:58.303+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:02:58.322+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:02:58.322+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:02:58.340+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.095 seconds
[2025-10-30T09:03:28.925+0000] {processor.py:186} INFO - Started process (PID=529) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:03:28.927+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:03:28.929+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:03:28.929+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:03:28.958+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:03:28.987+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:03:28.987+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:03:29.008+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:03:29.007+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:03:29.026+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.107 seconds
[2025-10-30T09:03:59.700+0000] {processor.py:186} INFO - Started process (PID=544) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:03:59.701+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:03:59.704+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:03:59.703+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:03:59.729+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:03:59.757+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:03:59.757+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:03:59.777+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:03:59.777+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:03:59.797+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.105 seconds
[2025-10-30T09:04:30.344+0000] {processor.py:186} INFO - Started process (PID=559) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:04:30.346+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:04:30.348+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:04:30.348+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:04:30.373+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:04:30.400+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:04:30.399+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:04:30.419+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:04:30.419+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:04:30.440+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.103 seconds
[2025-10-30T09:05:00.954+0000] {processor.py:186} INFO - Started process (PID=574) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:05:00.955+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:05:00.958+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:05:00.957+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:05:00.984+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:05:01.012+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:05:01.012+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:05:01.032+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:05:01.032+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:05:01.050+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.103 seconds
[2025-10-30T09:05:31.783+0000] {processor.py:186} INFO - Started process (PID=589) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:05:31.784+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:05:31.787+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:05:31.787+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:05:31.811+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:05:31.837+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:05:31.837+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:05:31.857+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:05:31.857+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:05:31.875+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.098 seconds
[2025-10-30T09:06:02.457+0000] {processor.py:186} INFO - Started process (PID=604) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:06:02.458+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:06:02.461+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:06:02.461+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:06:02.487+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:06:02.513+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:06:02.512+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:06:02.531+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:06:02.531+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:06:02.553+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.101 seconds
[2025-10-30T09:06:33.086+0000] {processor.py:186} INFO - Started process (PID=619) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:06:33.088+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:06:33.090+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:06:33.090+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:06:33.114+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:06:33.139+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:06:33.139+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:06:33.158+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:06:33.158+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:06:33.180+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.099 seconds
[2025-10-30T09:07:03.676+0000] {processor.py:186} INFO - Started process (PID=634) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:07:03.678+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:07:03.681+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:07:03.681+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:07:03.708+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:07:03.735+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:07:03.735+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:07:03.754+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:07:03.754+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:07:03.772+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.102 seconds
[2025-10-30T09:07:34.355+0000] {processor.py:186} INFO - Started process (PID=649) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:07:34.356+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:07:34.359+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:07:34.358+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:07:34.385+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:07:34.410+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:07:34.410+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:07:34.430+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:07:34.430+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:07:34.449+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.100 seconds
[2025-10-30T09:08:04.967+0000] {processor.py:186} INFO - Started process (PID=664) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:08:04.968+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:08:04.971+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:08:04.970+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:08:04.997+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:08:05.020+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:08:05.020+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:08:05.040+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:08:05.040+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:08:05.058+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.097 seconds
[2025-10-30T09:08:35.594+0000] {processor.py:186} INFO - Started process (PID=679) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:08:35.595+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:08:35.598+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:08:35.598+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:08:35.621+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:08:35.644+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:08:35.644+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:08:35.663+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:08:35.663+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:08:35.683+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.094 seconds
[2025-10-30T09:09:06.318+0000] {processor.py:186} INFO - Started process (PID=694) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:09:06.319+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:09:06.321+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:09:06.321+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:09:06.346+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:09:06.371+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:09:06.371+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:09:06.391+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:09:06.391+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:09:06.410+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.097 seconds
[2025-10-30T09:09:36.970+0000] {processor.py:186} INFO - Started process (PID=709) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:09:36.972+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:09:36.975+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:09:36.974+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:09:37.007+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:09:37.040+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:09:37.040+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:09:37.064+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:09:37.064+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:09:37.086+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.122 seconds
[2025-10-30T09:10:07.614+0000] {processor.py:186} INFO - Started process (PID=724) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:10:07.616+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:10:07.618+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:10:07.618+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:10:07.645+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:10:07.672+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:10:07.672+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:10:07.692+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:10:07.692+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:10:07.714+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.105 seconds
[2025-10-30T09:10:38.215+0000] {processor.py:186} INFO - Started process (PID=739) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:10:38.216+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:10:38.218+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:10:38.218+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:10:38.243+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:10:38.271+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:10:38.271+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:10:38.289+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:10:38.289+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:10:38.305+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.097 seconds
[2025-10-30T09:11:09.030+0000] {processor.py:186} INFO - Started process (PID=754) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:11:09.032+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:11:09.035+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:11:09.035+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:11:09.066+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:11:09.114+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:11:09.114+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:11:09.146+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:11:09.146+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:11:09.186+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.162 seconds
[2025-10-30T09:11:39.813+0000] {processor.py:186} INFO - Started process (PID=769) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:11:39.815+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:11:39.819+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:11:39.818+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:11:39.852+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:11:39.880+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:11:39.880+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:11:39.900+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:11:39.900+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:11:39.924+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.119 seconds
[2025-10-30T09:12:10.457+0000] {processor.py:186} INFO - Started process (PID=784) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:12:10.458+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:12:10.460+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:12:10.460+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:12:10.488+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:12:10.518+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:12:10.518+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:12:10.546+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:12:10.546+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:12:10.574+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.122 seconds
[2025-10-30T09:12:41.108+0000] {processor.py:186} INFO - Started process (PID=799) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:12:41.109+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:12:41.112+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:12:41.112+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:12:41.139+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:12:41.166+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:12:41.166+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:12:41.186+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:12:41.186+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:12:41.204+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.103 seconds
[2025-10-30T09:13:11.772+0000] {processor.py:186} INFO - Started process (PID=952) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:13:11.773+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:13:11.780+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:13:11.778+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:13:11.828+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:13:11.864+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:13:11.864+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:13:11.896+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:13:11.896+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:13:11.919+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.156 seconds
[2025-10-30T09:13:42.510+0000] {processor.py:186} INFO - Started process (PID=980) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:13:42.512+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:13:42.516+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:13:42.516+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:13:42.550+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:13:42.583+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:13:42.582+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:13:42.608+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:13:42.607+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:13:42.633+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.129 seconds
[2025-10-30T09:14:09.030+0000] {processor.py:186} INFO - Started process (PID=1092) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:14:09.032+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:14:09.035+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:14:09.035+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:14:09.084+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:14:09.206+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:14:09.206+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:14:09.229+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:14:09.229+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:14:09.266+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.242 seconds
[2025-10-30T09:14:11.092+0000] {processor.py:186} INFO - Started process (PID=1097) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:14:11.094+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:14:11.097+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:14:11.096+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:14:11.150+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:14:11.165+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:14:11.164+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:14:11.188+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:14:11.187+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:14:11.219+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.133 seconds
[2025-10-30T09:14:13.137+0000] {processor.py:186} INFO - Started process (PID=1102) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:14:13.139+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:14:13.142+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:14:13.142+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:14:13.189+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:14:13.207+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:14:13.207+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:14:13.231+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:14:13.231+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:14:13.260+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.129 seconds
[2025-10-30T09:14:43.825+0000] {processor.py:186} INFO - Started process (PID=1141) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:14:43.826+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:14:43.829+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:14:43.829+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:14:43.854+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:14:43.953+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:14:43.953+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:14:43.969+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:14:43.969+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:14:43.989+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.170 seconds
[2025-10-30T09:15:48.038+0000] {processor.py:186} INFO - Started process (PID=172) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:15:48.040+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:15:48.045+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:15:48.043+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:15:48.090+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:15:48.314+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:15:48.314+0000] {override.py:1900} INFO - Created Permission View: can edit on DAG:spark_etl_pipeline
[2025-10-30T09:15:48.328+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:15:48.328+0000] {override.py:1900} INFO - Created Permission View: can read on DAG:spark_etl_pipeline
[2025-10-30T09:15:48.342+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:15:48.341+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG:spark_etl_pipeline
[2025-10-30T09:15:48.370+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:15:48.370+0000] {override.py:1900} INFO - Created Permission View: can create on DAG Run:spark_etl_pipeline
[2025-10-30T09:15:48.381+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:15:48.380+0000] {override.py:1900} INFO - Created Permission View: can read on DAG Run:spark_etl_pipeline
[2025-10-30T09:15:48.391+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:15:48.390+0000] {override.py:1900} INFO - Created Permission View: menu access on DAG Run:spark_etl_pipeline
[2025-10-30T09:15:48.400+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:15:48.400+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG Run:spark_etl_pipeline
[2025-10-30T09:15:48.402+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:15:48.401+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:15:48.415+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:15:48.415+0000] {dag.py:3252} INFO - Creating ORM DAG for spark_etl_pipeline
[2025-10-30T09:15:48.428+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:15:48.428+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:15:48.458+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.428 seconds
[2025-10-30T09:16:18.623+0000] {processor.py:186} INFO - Started process (PID=233) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:16:18.625+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:16:18.633+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:16:18.632+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:16:18.690+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:16:18.758+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:16:18.757+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:16:18.867+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:16:18.866+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:16:18.919+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.307 seconds
[2025-10-30T09:16:34.165+0000] {processor.py:186} INFO - Started process (PID=253) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:16:34.167+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:16:34.169+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:16:34.169+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:16:34.211+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:16:34.248+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:16:34.247+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:16:34.276+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:16:34.276+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:16:34.310+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.151 seconds
[2025-10-30T09:17:04.899+0000] {processor.py:186} INFO - Started process (PID=326) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:17:04.900+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:17:04.902+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:17:04.902+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:17:04.929+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:17:04.956+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:17:04.956+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:17:04.975+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:17:04.975+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:17:04.993+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.101 seconds
[2025-10-30T09:17:35.631+0000] {processor.py:186} INFO - Started process (PID=353) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:17:35.633+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:17:35.635+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:17:35.635+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:17:35.660+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:17:35.684+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:17:35.684+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:17:35.703+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:17:35.703+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:17:35.725+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.099 seconds
[2025-10-30T09:18:06.386+0000] {processor.py:186} INFO - Started process (PID=413) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:18:06.387+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:18:06.390+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:18:06.390+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:18:06.420+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:18:06.449+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:18:06.449+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:18:06.472+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:18:06.472+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:18:06.496+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.117 seconds
[2025-10-30T09:18:15.878+0000] {processor.py:186} INFO - Started process (PID=428) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:18:15.880+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:18:15.882+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:18:15.882+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:18:15.924+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:18:16.031+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:18:16.030+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:18:16.052+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:18:16.052+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:18:16.079+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.207 seconds
[2025-10-30T09:18:19.079+0000] {processor.py:186} INFO - Started process (PID=433) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:18:19.080+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:18:19.083+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:18:19.082+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:18:19.128+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:18:19.141+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:18:19.141+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:18:19.160+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:18:19.160+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:18:19.183+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.111 seconds
[2025-10-30T09:18:49.902+0000] {processor.py:186} INFO - Started process (PID=460) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:18:49.904+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:18:49.907+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:18:49.906+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:18:49.934+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:18:50.036+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:18:50.036+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:18:50.055+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:18:50.055+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:18:50.085+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.189 seconds
[2025-10-30T09:18:53.178+0000] {processor.py:186} INFO - Started process (PID=470) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:18:53.180+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:18:53.182+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:18:53.181+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:18:53.219+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:18:53.232+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:18:53.232+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:18:53.251+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:18:53.251+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:18:53.273+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.101 seconds
[2025-10-30T09:19:23.814+0000] {processor.py:186} INFO - Started process (PID=645) to work on /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:19:23.815+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_etl_pipeline.py for tasks to queue
[2025-10-30T09:19:23.818+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:19:23.818+0000] {dagbag.py:587} INFO - Filling up the DagBag from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:19:23.852+0000] {processor.py:925} INFO - DAG(s) 'spark_etl_pipeline' retrieved from /opt/airflow/dags/spark_etl_pipeline.py
[2025-10-30T09:19:23.879+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:19:23.878+0000] {dag.py:3229} INFO - Sync 1 DAGs
[2025-10-30T09:19:23.898+0000] {logging_mixin.py:190} INFO - [2025-10-30T09:19:23.898+0000] {dag.py:4156} INFO - Setting next_dagrun for spark_etl_pipeline to 2025-10-29 00:00:00+00:00, run_after=2025-10-30 00:00:00+00:00
[2025-10-30T09:19:23.919+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_etl_pipeline.py took 0.111 seconds
